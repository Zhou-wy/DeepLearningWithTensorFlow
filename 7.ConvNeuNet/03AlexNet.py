# -*- coding: utf-8 -*-
"""AlexNet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/154j8mt7UzfiWGFqMfchUKxei3X3yUFg-
"""

# Commented out IPython magic to ensure Python compatibility.
# -*- coding: utf-8 -*-
import tensorflow as tf
import tensorflow.keras as keras
import numpy as np
import pandas as pd
import time
from matplotlib import pyplot as plt

# %matplotlib inline

net = keras.models.Sequential([
    keras.layers.Conv2D(filters=96, kernel_size=11, strides=4, activation='relu'),
    keras.layers.MaxPool2D(pool_size=3, strides=2),
    keras.layers.Conv2D(filters=256, kernel_size=5, padding="same", activation='relu'),
    keras.layers.MaxPool2D(pool_size=3, strides=2),
    keras.layers.Conv2D(filters=384, kernel_size=3, padding="valid", activation='relu'),
    keras.layers.Conv2D(filters=384, kernel_size=3, padding="valid", activation='relu'),
    keras.layers.Conv2D(filters=256, kernel_size=3, padding="valid", activation='relu'),
    keras.layers.MaxPool2D(pool_size=3, strides=2),
    keras.layers.Flatten(),
    keras.layers.Dense(4096, activation='relu'),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(4096, activation='relu'),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(10, activation='sigmoid')
])


class DataLoader():
    def __init__(self):
        fashion_mnist = tf.keras.datasets.fashion_mnist
        (self.train_images, self.train_labels), (self.test_images, self.test_labels) = fashion_mnist.load_data()
        self.train_images = np.expand_dims(self.train_images.astype(np.float32) / 255.0, axis=-1)
        self.test_images = np.expand_dims(self.test_images.astype(np.float32) / 255.0, axis=-1)
        self.train_labels = self.train_labels.astype(np.int32)
        self.test_labels = self.test_labels.astype(np.int32)
        self.num_train, self.num_test = self.train_images.shape[0], self.test_images.shape[0]

    def get_batch_train(self, batch_size):
        index = np.random.randint(0, np.shape(self.train_images)[0], batch_size)
        # need to resize images to (224,224)
        resized_images = tf.image.resize_with_pad(self.train_images[index], 224, 224, )
        return resized_images.numpy(), self.train_labels[index]

    def get_batch_test(self, batch_size):
        index = np.random.randint(0, np.shape(self.test_images)[0], batch_size)
        # need to resize images to (224,224)
        resized_images = tf.image.resize_with_pad(self.test_images[index], 224, 224, )
        return resized_images.numpy(), self.test_labels[index]


batch_size = 128
data = DataLoader()
x_train_batch, y_train_batch = data.get_batch_train(batch_size)
x_test_batch, y_test_batch = data.get_batch_test(batch_size)
print(x_train_batch.shape, y_train_batch.shape)
print(x_test_batch.shape, y_test_batch.shape)

t1 = time.time()
optimizer = keras.optimizers.SGD(learning_rate=0.013, momentum=0.0, nesterov=0.0)
net.compile(optimizer=optimizer, loss=keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])
net.build(input_shape=(None, 224, 224, 1))
his = net.fit(x_train_batch, y_train_batch, epochs=30, batch_size=1, validation_data=(x_test_batch, y_test_batch))
t2 = time.time()
print("训练所耗时间：%5.3f" % (t2 - t1))
net.save_weights("AlexNetWeights.h5")


def plot_learning_curves(history):
    pd.DataFrame(history.history).plot(figsize=(8, 5))
    plt.grid(True)
    plt.gca().set_ylim(0, 2.5)
    plt.show()


plot_learning_curves(his)
